{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_11136\\391125704.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Motor_Vehicle_Collisions.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Motor_Vehicle_Collisions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sure, these columns will be of no use\n",
    "columns_to_drop = [\n",
    "    'ZIP CODE',\n",
    "    'ON STREET NAME',\n",
    "    'CROSS STREET NAME',\n",
    "    'OFF STREET NAME',\n",
    "    'COLLISION_ID',\n",
    "    'CONTRIBUTING FACTOR VEHICLE 2',\n",
    "    'CONTRIBUTING FACTOR VEHICLE 3',\n",
    "    'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "    'CONTRIBUTING FACTOR VEHICLE 5',\n",
    "    'VEHICLE TYPE CODE 1',\n",
    "    'VEHICLE TYPE CODE 2',\n",
    "    'VEHICLE TYPE CODE 3',\n",
    "    'VEHICLE TYPE CODE 4',\n",
    "    'VEHICLE TYPE CODE 5'\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Missing Values: BOROUGH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's delete the observation with no LOCATION. They are a very small percentage of the total number of accidents (all below 5% per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with null LOCATION after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['LOCATION'])\n",
    "# Verify the result\n",
    "print(\"Number of rows with null LOCATION after dropping:\", df['LOCATION'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain:\n",
    "- missing_location_df: those observations that have missing BOROUGH but not missing LOCATION.\n",
    "- training_df: those observation to train the KNN with. The don't have NaN BOROUGH nor LOCATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (1929241, 15)\n",
      "Missing Borough df shape: (468030, 15)\n",
      "Training df shape: (1461211, 15)\n"
     ]
    }
   ],
   "source": [
    "df['LOCATION'].isnull().sum()\n",
    "\n",
    "# Data set with the NaN location values\n",
    "missing_location_df = df[(df['BOROUGH'].isnull())&(df['LOCATION'].notnull())]\n",
    "\n",
    "# Data set we will use to train our KNN model\n",
    "training_df = df[(df['BOROUGH'].notnull())&(df['LOCATION'].notnull())]\n",
    "\n",
    "# Display the shapes to verify (optional)\n",
    "print(f\"Original df shape: {df.shape}\")\n",
    "print(f\"Missing Borough df shape: {missing_location_df.shape}\")\n",
    "print(f\"Training df shape: {training_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize/scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features for training\n",
    "X = training_df[['LATITUDE', 'LONGITUDE']]\n",
    "y = training_df['BOROUGH']  # Target variable\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# For prediction data\n",
    "X_pred = missing_location_df[['LATITUDE', 'LONGITUDE']]\n",
    "X_pred_scaled = scaler.transform(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold-out method for validation: 80% train, 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9973173010131979\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        BRONX       1.00      1.00      1.00     43321\n",
      "     BROOKLYN       0.99      1.00      1.00     93560\n",
      "    MANHATTAN       1.00      1.00      1.00     64606\n",
      "       QUEENS       1.00      1.00      1.00     78516\n",
      "STATEN ISLAND       1.00      1.00      1.00     12240\n",
      "\n",
      "     accuracy                           1.00    292243\n",
      "    macro avg       1.00      1.00      1.00    292243\n",
      " weighted avg       1.00      1.00      1.00    292243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=17)\n",
    "\n",
    "# Initialize and train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few predictions for missing boroughs:\n",
      "     LATITUDE  LONGITUDE PREDICTED_BOROUGH\n",
      "12  40.709183 -73.956825          BROOKLYN\n",
      "16  40.701275 -73.888870            QUEENS\n",
      "19  40.596620 -74.002310          BROOKLYN\n",
      "25  40.783268 -73.824850            QUEENS\n",
      "27  40.744644 -73.770410            QUEENS\n"
     ]
    }
   ],
   "source": [
    "# Create a proper copy of the DataFrame for predictions\n",
    "missing_location_df_copy = missing_location_df.copy()\n",
    "\n",
    "# Now predict the boroughs for the missing values\n",
    "missing_borough_predictions = knn.predict(X_pred_scaled)\n",
    "\n",
    "# Add predictions to the copy\n",
    "missing_location_df_copy.loc[:, 'PREDICTED_BOROUGH'] = missing_borough_predictions\n",
    "\n",
    "# Optional: Display the first few predictions\n",
    "print(\"\\nFirst few predictions for missing boroughs:\")\n",
    "print(missing_location_df_copy[['LATITUDE', 'LONGITUDE', 'PREDICTED_BOROUGH']].head())\n",
    "\n",
    "# Fill the rows with the imputed BOROUGH values\n",
    "df.loc[missing_location_df.index, 'BOROUGH'] = missing_location_df_copy['PREDICTED_BOROUGH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "Drop the rest of rows with NaN values (victims features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['NUMBER OF PERSONS INJURED','NUMBER OF PERSONS KILLED','CONTRIBUTING FACTOR VEHICLE 1', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing: CONTRIBUTING FACTOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922359"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unspecified', 'Passing Too Closely', 'Driver Inexperience',\n",
       "       'Passing or Lane Usage Improper', 'Turning Improperly',\n",
       "       'Unsafe Speed', 'Reaction to Uninvolved Vehicle',\n",
       "       'Steering Failure', 'Following Too Closely', 'Other Vehicular',\n",
       "       'Driver Inattention/Distraction', 'Oversized Vehicle',\n",
       "       'Traffic Control Disregarded', 'Unsafe Lane Changing',\n",
       "       'Alcohol Involvement', 'View Obstructed/Limited',\n",
       "       'Failure to Yield Right-of-Way', 'Aggressive Driving/Road Rage',\n",
       "       'Pavement Slippery', 'Illnes', 'Lost Consciousness',\n",
       "       'Brakes Defective', 'Backing Unsafely', 'Passenger Distraction',\n",
       "       'Fell Asleep',\n",
       "       'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion',\n",
       "       'Obstruction/Debris', 'Tinted Windows', 'Animals Action',\n",
       "       'Drugs (illegal)', 'Pavement Defective', 'Other Lighting Defects',\n",
       "       'Outside Car Distraction', 'Driverless/Runaway Vehicle',\n",
       "       'Tire Failure/Inadequate', 'Fatigued/Drowsy',\n",
       "       'Headlights Defective', 'Accelerator Defective',\n",
       "       'Physical Disability', 'Glare', 'Eating or Drinking',\n",
       "       'Failure to Keep Right', 'Cell Phone (hands-free)',\n",
       "       'Lane Marking Improper/Inadequate', 'Cell Phone (hand-Held)',\n",
       "       'Using On Board Navigation Device', 'Other Electronic Device',\n",
       "       'Tow Hitch Defective', 'Windshield Inadequate',\n",
       "       'Vehicle Vandalism', 'Prescription Medication',\n",
       "       'Shoulders Defective/Improper', 'Listening/Using Headphones',\n",
       "       'Traffic Control Device Improper/Non-Working', 'Texting',\n",
       "       'Reaction to Other Uninvolved Vehicle', '80', '1',\n",
       "       'Drugs (Illegal)', 'Illness', 'Cell Phone (hand-held)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CONTRIBUTING FACTOR VEHICLE 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['CONTRIBUTING FACTOR VEHICLE 1']=='1').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING_FACTOR_GROUP\n",
      "Unspecified                   645415\n",
      "Traffic Violations            420333\n",
      "Driver Attention Issues       417846\n",
      "Driver Skill Issues           169923\n",
      "Driver Impairment              97353\n",
      "External Factors               91155\n",
      "Road Infrastructure            25288\n",
      "Visibility Issues              17223\n",
      "Vehicle Issues                 13144\n",
      "Vehicle Mechanical Failure     13043\n",
      "Health Issues                  11636\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "\n",
    "# Create a mapping dictionary to group similar contributing factors\n",
    "contributing_factor_mapping = {\n",
    "    # Driver Behavior - Attention\n",
    "    'Driver Inattention/Distraction': 'Driver Attention Issues',\n",
    "    'Passenger Distraction': 'Driver Attention Issues',\n",
    "    'Outside Car Distraction': 'Driver Attention Issues',\n",
    "    'Cell Phone (hands-free)': 'Driver Attention Issues',\n",
    "    'Cell Phone (hand-Held)': 'Driver Attention Issues',\n",
    "    'Cell Phone (hand-held)': 'Driver Attention Issues',\n",
    "    'Using On Board Navigation Device': 'Driver Attention Issues',\n",
    "    'Other Electronic Device': 'Driver Attention Issues',\n",
    "    'Listening/Using Headphones': 'Driver Attention Issues',\n",
    "    'Texting': 'Driver Attention Issues',\n",
    "    'Eating or Drinking': 'Driver Attention Issues',\n",
    "    \n",
    "    # Driver Behavior - Impairment\n",
    "    'Alcohol Involvement': 'Driver Impairment',\n",
    "    'Drugs (illegal)': 'Driver Impairment',\n",
    "    'Drugs (Illegal)': 'Driver Impairment',\n",
    "    'Fell Asleep': 'Driver Impairment',\n",
    "    'Fatigued/Drowsy': 'Driver Impairment',\n",
    "    'Lost Consciousness': 'Driver Impairment',\n",
    "    'Prescription Medication': 'Driver Impairment',\n",
    "    \n",
    "    # Driver Behavior - Aggression/Violations\n",
    "    'Unsafe Speed': 'Traffic Violations',\n",
    "    'Following Too Closely': 'Traffic Violations',\n",
    "    'Passing Too Closely': 'Traffic Violations',\n",
    "    'Traffic Control Disregarded': 'Traffic Violations',\n",
    "    'Failure to Yield Right-of-Way': 'Traffic Violations',\n",
    "    'Aggressive Driving/Road Rage': 'Traffic Violations',\n",
    "    'Failure to Keep Right': 'Traffic Violations',\n",
    "    'Backing Unsafely': 'Traffic Violations',\n",
    "    \n",
    "    # Driver Skill/Experience\n",
    "    'Driver Inexperience': 'Driver Skill Issues',\n",
    "    'Turning Improperly': 'Driver Skill Issues',\n",
    "    'Passing or Lane Usage Improper': 'Driver Skill Issues',\n",
    "    'Unsafe Lane Changing': 'Driver Skill Issues',\n",
    "    \n",
    "    # Vehicle Issues\n",
    "    'Steering Failure': 'Vehicle Mechanical Failure',\n",
    "    'Brakes Defective': 'Vehicle Mechanical Failure',\n",
    "    'Tire Failure/Inadequate': 'Vehicle Mechanical Failure',\n",
    "    'Headlights Defective': 'Vehicle Mechanical Failure',\n",
    "    'Accelerator Defective': 'Vehicle Mechanical Failure',\n",
    "    'Tow Hitch Defective': 'Vehicle Mechanical Failure',\n",
    "    'Windshield Inadequate': 'Vehicle Mechanical Failure',\n",
    "    'Other Lighting Defects': 'Vehicle Mechanical Failure',\n",
    "    'Oversized Vehicle': 'Vehicle Issues',\n",
    "    'Driverless/Runaway Vehicle': 'Vehicle Issues',\n",
    "    'Vehicle Vandalism': 'Vehicle Issues',\n",
    "    'Tinted Windows': 'Vehicle Issues',\n",
    "    \n",
    "    # Environmental Factors\n",
    "    'Pavement Slippery': 'Road Infrastructure',\n",
    "    'Pavement Defective': 'Road Infrastructure',\n",
    "    'View Obstructed/Limited': 'Visibility Issues',\n",
    "    'Glare': 'Visibility Issues',\n",
    "    'Obstruction/Debris': 'Road Infrastructure',\n",
    "    'Lane Marking Improper/Inadequate': 'Road Infrastructure',\n",
    "    'Shoulders Defective/Improper': 'Road Infrastructure',\n",
    "    'Traffic Control Device Improper/Non-Working': 'Road Infrastructure',\n",
    "    \n",
    "    # Health/Physical Issues\n",
    "    'Illnes': 'Health Issues',\n",
    "    'Illness': 'Health Issues',\n",
    "    'Physical Disability': 'Health Issues',\n",
    "    \n",
    "    # External Factors\n",
    "    'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion': 'External Factors',\n",
    "    'Animals Action': 'External Factors',\n",
    "    'Other Vehicular': 'External Factors',\n",
    "    'Reaction to Uninvolved Vehicle': 'External Factors',\n",
    "    'Reaction to Other Uninvolved Vehicle': 'External Factors',\n",
    "    \n",
    "    # Other/Unspecified\n",
    "    'Unspecified': 'Unspecified',\n",
    "    '80': 'Unspecified',  # Likely data entry errors\n",
    "    '1': 'Unspecified'    # Likely data entry errors\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new column with grouped factors\n",
    "df_new['CONTRIBUTING_FACTOR_GROUP'] = df_new['CONTRIBUTING FACTOR VEHICLE 1'].map(contributing_factor_mapping)\n",
    "\n",
    "# Handle any unmapped values (if any new categories appear)\n",
    "unmapped = df_new[df_new['CONTRIBUTING_FACTOR_GROUP'].isna()]['CONTRIBUTING FACTOR VEHICLE 1'].unique()\n",
    "if len(unmapped) > 0:\n",
    "    print(\"Unmapped contributing factors:\", unmapped)\n",
    "    # Assign unmapped values to 'Other' category\n",
    "    ddf_newf['CONTRIBUTING_FACTOR_GROUP'] = df_new['CONTRIBUTING_FACTOR_GROUP'].fillna('Other')\n",
    "\n",
    "# Count the frequency of each group\n",
    "factor_group_counts = df_new['CONTRIBUTING_FACTOR_GROUP'].value_counts()\n",
    "print(factor_group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of CRASH DATE column: datetime64[ns]\n",
      "\n",
      "Sample of converted dates:\n",
      "2101610   2012-07-01\n",
      "2102086   2012-07-01\n",
      "2102092   2012-07-01\n",
      "2102103   2012-07-01\n",
      "2102111   2012-07-01\n",
      "Name: CRASH DATE, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert CRASH DATE to datetime\n",
    "df_new['CRASH DATE'] = pd.to_datetime(df_new['CRASH DATE'], format='%m/%d/%Y')\n",
    "\n",
    "# Sort the DataFrame by CRASH DATE\n",
    "df_new = df_new.sort_values('CRASH DATE')\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"Data type of CRASH DATE column:\", df_new['CRASH DATE'].dtype)\n",
    "print(\"\\nSample of converted dates:\")\n",
    "print(df_new['CRASH DATE'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2101610    7\n",
       "2102086    7\n",
       "2102092    7\n",
       "2102103    7\n",
       "2102111    7\n",
       "          ..\n",
       "2168948    4\n",
       "2168949    4\n",
       "2162987    4\n",
       "2168937    4\n",
       "2169086    4\n",
       "Name: CRASH DATE, Length: 1922359, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['CRASH DATE'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('weather_means_2016_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'temperature_2m (°C)', 'precipitation (mm)',\n",
       "       'rain (mm)', 'cloudcover (%)', 'cloudcover_low (%)',\n",
       "       'cloudcover_mid (%)', 'cloudcover_high (%)', 'windspeed_10m (km/h)',\n",
       "       'winddirection_10m (°)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>cloudcover (%)</th>\n",
       "      <th>cloudcover_low (%)</th>\n",
       "      <th>cloudcover_mid (%)</th>\n",
       "      <th>cloudcover_high (%)</th>\n",
       "      <th>windspeed_10m (km/h)</th>\n",
       "      <th>winddirection_10m (°)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.29</td>\n",
       "      <td>34.50</td>\n",
       "      <td>9.71</td>\n",
       "      <td>77.75</td>\n",
       "      <td>12.48</td>\n",
       "      <td>273.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.25</td>\n",
       "      <td>9.92</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.50</td>\n",
       "      <td>13.38</td>\n",
       "      <td>266.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.29</td>\n",
       "      <td>11.29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.75</td>\n",
       "      <td>244.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>11.83</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.85</td>\n",
       "      <td>313.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.65</td>\n",
       "      <td>304.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.79</td>\n",
       "      <td>12.67</td>\n",
       "      <td>45.54</td>\n",
       "      <td>40.12</td>\n",
       "      <td>7.55</td>\n",
       "      <td>218.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>76.17</td>\n",
       "      <td>46.79</td>\n",
       "      <td>64.38</td>\n",
       "      <td>54.25</td>\n",
       "      <td>7.89</td>\n",
       "      <td>220.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>94.33</td>\n",
       "      <td>72.29</td>\n",
       "      <td>51.29</td>\n",
       "      <td>59.00</td>\n",
       "      <td>6.28</td>\n",
       "      <td>64.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>6.95</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>100.00</td>\n",
       "      <td>92.67</td>\n",
       "      <td>86.88</td>\n",
       "      <td>50.92</td>\n",
       "      <td>4.31</td>\n",
       "      <td>156.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>98.88</td>\n",
       "      <td>95.67</td>\n",
       "      <td>29.21</td>\n",
       "      <td>39.67</td>\n",
       "      <td>6.49</td>\n",
       "      <td>200.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  temperature_2m (°C)  precipitation (mm)  rain (mm)  \\\n",
       "0     2016-01-01                 5.41                 0.0        0.0   \n",
       "1     2016-01-02                 2.39                 0.0        0.0   \n",
       "2     2016-01-03                 3.01                 0.0        0.0   \n",
       "3     2016-01-04                 0.10                 0.0        0.0   \n",
       "4     2016-01-05                -6.78                 0.0        0.0   \n",
       "...          ...                  ...                 ...        ...   \n",
       "2187  2021-12-27                 2.78                 0.0        0.0   \n",
       "2188  2021-12-28                 4.30                 2.2        2.2   \n",
       "2189  2021-12-29                 5.85                 5.1        5.1   \n",
       "2190  2021-12-30                 6.95                 2.4        2.4   \n",
       "2191  2021-12-31                 8.44                 0.5        0.5   \n",
       "\n",
       "      cloudcover (%)  cloudcover_low (%)  cloudcover_mid (%)  \\\n",
       "0              57.29               34.50                9.71   \n",
       "1              10.25                9.92                1.42   \n",
       "2              10.29               11.29                0.08   \n",
       "3              14.75               11.83                6.75   \n",
       "4               0.67                0.75                0.00   \n",
       "...              ...                 ...                 ...   \n",
       "2187           45.79               12.67               45.54   \n",
       "2188           76.17               46.79               64.38   \n",
       "2189           94.33               72.29               51.29   \n",
       "2190          100.00               92.67               86.88   \n",
       "2191           98.88               95.67               29.21   \n",
       "\n",
       "      cloudcover_high (%)  windspeed_10m (km/h)  winddirection_10m (°)  \n",
       "0                   77.75                 12.48                 273.33  \n",
       "1                    1.50                 13.38                 266.42  \n",
       "2                    0.00                 12.75                 244.38  \n",
       "3                    0.00                 16.85                 313.54  \n",
       "4                    0.00                 17.65                 304.25  \n",
       "...                   ...                   ...                    ...  \n",
       "2187                40.12                  7.55                 218.88  \n",
       "2188                54.25                  7.89                 220.96  \n",
       "2189                59.00                  6.28                  64.38  \n",
       "2190                50.92                  4.31                 156.29  \n",
       "2191                39.67                  6.49                 200.83  \n",
       "\n",
       "[2192 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using column merge with 'date' column\n",
      "Merge successful? Yes\n",
      "Original df_new shape: (1922359, 17)\n",
      "Merged DataFrame shape: (1922359, 27)\n",
      "Rows with missing weather data (date): 899951\n"
     ]
    }
   ],
   "source": [
    "# Check if 'date' is in df_weather columns\n",
    "if 'date' in df_weather.columns:\n",
    "    # If 'date' is a column in df_weather\n",
    "    print(\"Using column merge with 'date' column\")\n",
    "    \n",
    "    # Ensure both date columns are the same type\n",
    "    df_new['merge_date'] = pd.to_datetime(df_new['CRASH DATE']).dt.date\n",
    "    df_weather['date'] = pd.to_datetime(df_weather['date']).dt.date\n",
    "\n",
    "    # Merge using columns\n",
    "    df_merged = pd.merge(\n",
    "        df_new,\n",
    "        df_weather,\n",
    "        left_on='merge_date',\n",
    "        right_on='date',\n",
    "        how='left'\n",
    "    )\n",
    "else:\n",
    "    # If date is the index in df_weather\n",
    "    print(\"Using index merge with date index\")\n",
    "    \n",
    "    # Convert index to date objects if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df_weather.index):\n",
    "        df_weather.index = df_weather.index.date\n",
    "    \n",
    "    # Convert merge_date to same type as df_weather index\n",
    "    df_new['merge_date'] = pd.to_datetime(df_new['CRASH DATE']).dt.date\n",
    "    \n",
    "    # Merge using index\n",
    "    df_merged = pd.merge(\n",
    "        df_new,\n",
    "        df_weather,\n",
    "        left_on='merge_date',\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Check the result\n",
    "print(\"Merge successful?\", \"Yes\" if len(df_merged) > 0 else \"No\")\n",
    "print(\"Original df_new shape:\", df_new.shape)\n",
    "print(\"Merged DataFrame shape:\", df_merged.shape)\n",
    "\n",
    "# Check for missing values in the first weather column\n",
    "if len(df_weather.columns) > 0:\n",
    "    first_weather_col = df_weather.columns[0]\n",
    "    missing_count = df_merged[first_weather_col].isna().sum()\n",
    "    print(f\"Rows with missing weather data ({first_weather_col}): {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'LATITUDE', 'LONGITUDE',\n",
       "       'LOCATION', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
       "       'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
       "       'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
       "       'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED',\n",
       "       'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING_FACTOR_GROUP',\n",
       "       'merge_date', 'date', 'temperature_2m (°C)', 'precipitation (mm)',\n",
       "       'rain (mm)', 'cloudcover (%)', 'cloudcover_low (%)',\n",
       "       'cloudcover_mid (%)', 'cloudcover_high (%)', 'windspeed_10m (km/h)',\n",
       "       'winddirection_10m (°)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['merge_date', 'date']\n",
    "df_merged = df_merged.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'LATITUDE', 'LONGITUDE',\n",
       "       'LOCATION', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
       "       'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
       "       'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
       "       'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED',\n",
       "       'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING_FACTOR_GROUP',\n",
       "       'temperature_2m (°C)', 'precipitation (mm)', 'rain (mm)',\n",
       "       'cloudcover (%)', 'cloudcover_low (%)', 'cloudcover_mid (%)',\n",
       "       'cloudcover_high (%)', 'windspeed_10m (km/h)', 'winddirection_10m (°)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only the years where we have data with weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = df_merged[(df_merged['CRASH DATE'].dt.year>=2016)&(df_merged['CRASH DATE'].dt.year<=2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('merged_collisions_weather_2012-2024.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
